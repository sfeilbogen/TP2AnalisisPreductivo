# -*- coding: utf-8 -*-
"""TP2Feilbogen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MFmKxwoO6bRzinHDV5PKawSKejdWZHTk

Importamos librerias y las bases origen y testear
"""

!pip install feature-engine

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, ParameterGrid
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from feature_engine.preprocessing import MatchVariables
from feature_engine.encoding import RareLabelEncoder, OneHotEncoder,OrdinalEncoder, CountFrequencyEncoder
from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, RandomSampleImputer,EndTailImputer, MeanMedianImputer, ArbitraryNumberImputer
from sklearn_pandas import DataFrameMapper
from feature_engine.outliers import Winsorizer, OutlierTrimmer
from sklearn.preprocessing import MultiLabelBinarizer

from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import CountVectorizer
import datetime
from sklearn.compose import ColumnTransformer
from feature_engine.datetime import DatetimeFeatures
import pickle
from tempfile import mkdtemp
from shutil import rmtree
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
from sklearn import set_config
from sklearn.base import clone
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score

from feature_engine.transformation import PowerTransformer
from feature_engine.creation import RelativeFeatures
from feature_engine.selection import DropFeatures

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt

import matplotlib.pyplot as plt

pd.options.display.max_columns = None

db=pd.read_csv("origen.csv", sep=",")

db.shape

test=pd.read_csv("testear.csv", sep=",")

"""Estadisticas descriptivas principales"""

db.describe()

import matplotlib.pyplot as plt
import statsmodels.api as sm
corr = db.set_index('averageRating').corr()
sm.graphics.plot_corr(corr, xnames=list(corr.columns))
plt.show()

db.info()

base2=db[:]

base2.hist(bins=50, figsize=(10,10))
plt.show()

categorical_columnsdb = [c for c in db.columns if db[c].dtype == 'O']
numerical_columnsdb = [c for c in db.columns if db[c].dtype != 'O']
numerical_columnsdb

db.columns

"""Particionamos"""

X = db.drop(columns=['averageRating'])
y = db['averageRating']

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.25, random_state=33)

X_train.shape

y_val.shape

db.shape

categorical_columns = [c for c in X.columns if X[c].dtype == 'O']
numerical_columns = [c for c in X.columns if X[c].dtype != 'O']
numerical_columns

OHE=["titleType","language","adult","original_language","status","video"]
AMI=["attributes","overview","tagline"]
NUM=['numVotes', 'startYear', 'endYear', 'runtimeMinutes', 'seasonNumber', 'episodeNumber','ordering', 'budget', 'popularity', 'revenue', 'runtime',"isAdult","isOriginalTitle"]
BIN=["gg","dd","ww","release_date"]+OHE
U=["release_date"]+OHE

pipe = Pipeline([
    ('0', columnDropperTransformer(["Id"])), 
    ("2", EndTailImputer(imputation_method='gaussian', tail='right', fold=3, variables=NUM)),
    ('3', CategoricalImputer(fill_value="Missing", return_object=True, variables=BIN,ignore_format=True)),
    ('4', binarizer1),
    ('5', binarizer2),
    ('6', binarizer3),
    ('8', AddMissingIndicator(missing_only=False, variables=AMI)),
    ('9', columnDropperTransformer(["attributes","overview","tagline","genres_x","writers","directors","genres_y","production_companies","production_countries"])),
    ('10', OneHotEncoder(top_categories=3, drop_last=True, drop_last_binary=True, variables=U, ignore_format=False)),
    
])

class columnDropperTransformer():
    def __init__(self,columns):
        self.columns=columns

    def transform(self,X,y=None):
        return X.drop(self.columns,axis=1)

    def fit(self, X, y=None):
        return self

binarizer1 = DataFrameMapper([
     ("gg", MultiLabelBinarizer(
classes=["Comedy","Drama","Documentary","Action","Missing"])),
], df_out=True, default=None)

binarizer2 = DataFrameMapper([
     ("dd", MultiLabelBinarizer(
classes=["nm1337210","nm3766090","nm0123273","nm3005544","Missing"])),
], df_out=True, default=None)

binarizer3 = DataFrameMapper([
     ("ww", MultiLabelBinarizer(
classes=["nm3005544","nm3766090","nm1444457","nm1108327","Missing"])),
], df_out=True, default=None)

_=pipe[:5].fit(X_train, y_train)
pipe[:5].transform(X_train)
#pipe[:-1].get_feature_names_out()
#pipe[0].fit_transform(X)

set_config(display="diagram")
pipe

"""Fiteamos y transformamos"""

X_train["gg"] = X_train["genres_x"].str.split(",")
X_train["ww"] = X_train["writers"].str.split(",")
X_train["dd"] = X_train["directors"].str.split(",")

X_train["titleType"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["genres_x"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["directors"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["writers"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["language"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["attributes"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["adult"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["genres_y"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["original_language"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["overview"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["production_companies"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["production_countries"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["release_date"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["status"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["tagline"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_train["video"].replace(to_replace = 0, value = np.NaN, inplace=True)

_=pipe.fit(X_train, y_train)
 X_train_transformed = pipe.transform(X_train)

X_train_transformed.describe()

"""Modelo 1: DecisionTreeRegressor"""

parameters={"splitter":["best","random"],
            "max_depth" : [1,9,12],
           "min_samples_leaf":[1,2,4],
           "max_features":["auto","sqrt",None],
           
            }

regr_1 = DecisionTreeRegressor(max_depth=4)

M1 = GridSearchCV(regr_1, parameters)
#M1.fit(X_train_transformed, y_train)

M1.best_params_

"""RandomForestRegressor 1"""

parameters = {
    'n_estimators': [100, 300],
    'max_depth': [1,2,4],

}
regr_2 = RandomForestRegressor(random_state=0)

M2 = GridSearchCV(regr_2, parameters)
#M2.fit(X_train_transformed, y_train)

M2.best_params_

"""RandomForestRegressor 2, corrida 1"""

parameters = {
    'max_depth': [5, None],
    'min_samples_leaf': [1, 4],
    'n_estimators': [100, 200]}

regr_3 = RandomForestRegressor(random_state=0)
M3 = GridSearchCV(regr_3, parameters)
#M3.fit(X_train_transformed, y_train)

M3.best_params_

"""Corrida 2"""

parameters4 = {
    'max_depth': [5, None],
    'min_samples_leaf': [1, 4],
    'n_estimators': [100, 200]}

regr_4 = RandomForestRegressor(random_state=0)
M4 = GridSearchCV(regr_4, parameters4)
#M4.fit(X_train_transformed, y_train)

M4.best_params_

M1=DecisionTreeRegressor(max_depth=12, max_features=None, min_samples_leaf= 4, splitter= 'best')

M2 = RandomForestRegressor(max_depth= 4,n_estimators=100)

M3 = RandomForestRegressor(max_depth= 10, min_samples_leaf= 4, n_estimators= 200)

M4 = RandomForestRegressor(max_depth= None, min_samples_leaf= 4, n_estimators= 200)

model4 = RandomForestRegressor(max_depth= None, min_samples_leaf= 4, n_estimators= 200)

modelo5=DecisionTreeRegressor(max_depth=12,
 max_features=None,
 min_samples_leaf= 4,
 splitter= 'best')

"""Fiteamos"""

_ = M1.fit(X_train_transformed, y_train)

_ = M2.fit(X_train_transformed, y_train)

_ = M3.fit(X_train_transformed, y_train)

_ = M4.fit(X_train_transformed, y_train)

_ = model4.fit(X_train_transformed, y_train)

_ = modelo5.fit(X_train_transformed, y_train)

X_val["gg"] = X_val["genres_x"].str.split(",")
X_val["ww"] = X_val["writers"].str.split(",")
X_val["dd"] = X_val["directors"].str.split(",")

X_val["titleType"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["genres_x"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["directors"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["writers"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["language"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["attributes"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["adult"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["genres_y"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["original_language"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["overview"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["production_companies"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["production_countries"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["release_date"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["status"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["tagline"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["video"].replace(to_replace = 0, value = np.NaN, inplace=True)

X_val_transformed = pipe.transform(X_val)
y_val_pred = M1.predict(X_val_transformed)

X_val_transformed = pipe.transform(X_val)
y_val_pred = M2.predict(X_val_transformed)

X_val_transformed = pipe.transform(X_val)
y_val_pred = M3.predict(X_val_transformed)

X_val_transformed = pipe.transform(X_val)
y_val_pred = M4.predict(X_val_transformed)

X_val_transformed = pipe.transform(X_val)
y_val_pred = model4.predict(X_val_transformed)

X_val_transformed = pipe.transform(X_val)
y_val_pred = modelo5.predict(X_val_transformed)

X_val_transformed

y_val_pred[:5]

print(M1.score(X_val_transformed,y_val))

print(M2.score(X_val_transformed,y_val))

print(M3.score(X_val_transformed,y_val))

print(M4.score(X_val_transformed,y_val))

print(model4.score(X_val_transformed,y_val))

print(model4.score(X_val_transformed,y_val))

print(modelo5.score(X_val_transformed,y_val))

print(modelo5.score(X_val_transformed,y_val))

test["gg"] = test["genres_x"].str.split(",")
test["ww"] = test["writers"].str.split(",")
test["dd"] = test["directors"].str.split(",")

test["titleType"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["genres_x"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["directors"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["writers"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["language"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["attributes"].replace(to_replace = 0, value = np.NaN, inplace=True)
test["adult"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["genres_y"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["original_language"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["overview"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["production_companies"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["production_countries"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["release_date"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["status"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["tagline"].replace(to_replace = 0, value = np.NaN, inplace=True)
X_val["video"].replace(to_replace = 0, value = np.NaN, inplace=True)

test_t = pipe.transform(test)

y_test_pred=model4.predict(test_t)

salida = pd.DataFrame(data={"averageRating": y_test_pred}).astype(str)
salida.index = test.Id
salida.to_csv("Linear_Reg.csv", sep=',',index=True,  index_label='Id')